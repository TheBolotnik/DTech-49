import streamlit as st
import numpy as np
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split


# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="–û–±—É—á–µ–Ω–∏–µ –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏", layout="centered")
st.title("ü§ñ –ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤–µ—Å–∞ –Ω–æ–≤–æ—Ä–æ–∂–¥—ë–Ω–Ω–æ–≥–æ")

# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
st.sidebar.header("üîß –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏")
max_depth = st.sidebar.slider("–ú–∞–∫—Å. –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞", 2, 10, 5)
learning_rate = st.sidebar.slider("–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è", 0.01, 0.5, 0.1)
reg_lambda = st.sidebar.slider("L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (lambda)", 0.0, 10.0, 1.0)
alpha = st.sidebar.slider("L1-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (alpha)", 0.0, 10.0, 0.0)

# –§—É–Ω–∫—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤–µ—Å–∞
def classify_weight(bwt_grams):
    if bwt_grams < 2500:
        return 0
    elif 2500 <= bwt_grams < 3000:
        return 1
    elif 3000 <= bwt_grams <= 4000:
        return 2
    else:
        return 3

class_labels = {
    0: "–ù–∏–∑–∫–∏–π (<2500 –≥)",
    1: "–ü–æ–Ω–∏–∂–µ–Ω–Ω—ã–π (2500‚Äì2999 –≥)",
    2: "–ù–æ—Ä–º–∞–ª—å–Ω—ã–π (3000‚Äì4000 –≥)",
    3: "–ò–∑–±—ã—Ç–æ—á–Ω—ã–π (>4000 –≥)"
}

# === 1. –ó–∞–≥—Ä—É–∑–∫–∞ CSV –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ===
st.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
uploaded_train = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±—É—á–∞—é—â–∏–π CSV-—Ñ–∞–π–ª (—Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: bwt, gestation, parity, age, height, weight, smoke)", type="csv")

model = None  # —Å–æ–∑–¥–∞–¥–∏–º –≥–ª–æ–±–∞–ª—å–Ω–æ, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è

if uploaded_train:
    df = pd.read_csv(uploaded_train)
    required_cols = ['bwt', 'gestation', 'parity', 'age', 'height', 'weight', 'smoke']
    if not all(col in df.columns for col in required_cols):
        st.error(f"‚ùå –û—à–∏–±–∫–∞: —Ç—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫: {', '.join(required_cols)}")
    else:
        st.success("‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")

        df.dropna(inplace=True)
        df['bwt_grams'] = df['bwt'] * 28.35
        df['weight_class'] = df['bwt_grams'].apply(classify_weight)

        features = ['gestation', 'parity', 'age', 'height', 'weight', 'smoke']
        X = df[features]
        y = df['weight_class']

        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞
        smote = SMOTE(random_state=42)
        X_balanced, y_balanced = smote.fit_resample(X_scaled, y)

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced
        )

        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = XGBClassifier(
            objective='multi:softmax',
            num_class=4,
            eval_metric='mlogloss',
            max_depth=max_depth,
            learning_rate=learning_rate,
            reg_lambda=reg_lambda,
            alpha=alpha
        )
        model.fit(X_train, y_train)
        st.success("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!")

        # –ú–µ—Ç—Ä–∏–∫–∏
        y_pred = model.predict(X_test)
        st.subheader("üìä –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á—ë—Ç")
        st.text(classification_report(y_test, y_pred, target_names=class_labels.values()))

        st.subheader("üìâ –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
        cm = confusion_matrix(y_test, y_pred)
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels.values(), yticklabels=class_labels.values())
        ax.set_xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ")
        ax.set_ylabel("–ò—Å—Ç–∏–Ω–Ω–æ")
        st.pyplot(fig)

# === 2. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö ===
st.header("üîç –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
uploaded_infer = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (gestation, parity, age, height, weight, smoke)", type="csv", key="infer")

if uploaded_infer:
    if model is None:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å, –∑–∞–≥—Ä—É–∑–∏–≤ –æ–±—É—á–∞—é—â–∏–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –≤—ã—à–µ.")
    else:
        df_new = pd.read_csv(uploaded_infer)
        required_infer_cols = ['gestation', 'parity', 'age', 'height', 'weight', 'smoke']

        if not all(col in df_new.columns for col in required_infer_cols):
            st.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(required_infer_cols)}")
        else:
            st.success("‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
            scaler = StandardScaler()
            X_new_scaled = scaler.fit_transform(df_new[required_infer_cols])
            y_new_pred = model.predict(X_new_scaled)

            df_new['–ü—Ä–æ–≥–Ω–æ–∑_–≤–µ—Å–∞'] = [class_labels[p] for p in y_new_pred]
            st.subheader("üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
            st.dataframe(df_new)

            st.download_button(
                label="üì• –°–∫–∞—á–∞—Ç—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏",
                data=df_new.to_csv(index=False).encode('utf-8'),
                file_name="predictions.csv",
                mime="text/csv"
            )

            fig2, ax2 = plt.subplots()
            sns.countplot(x=df_new['–ü—Ä–æ–≥–Ω–æ–∑_–≤–µ—Å–∞'], ax=ax2)
            ax2.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤")
            st.pyplot(fig2)
